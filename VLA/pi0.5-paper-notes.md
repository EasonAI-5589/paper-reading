# π₀.₅: A Vision-Language-Action Model with Open-World Generalization

> Physical Intelligence, 2025
> arXiv:2504.16054

## 一句话总结

Physical Intelligence 在 π₀ 基础上提出 π₀.₅，通过异构数据协同训练（多机器人数据 + 高层语义预测 + Web 数据 + 语音指令）实现开放世界泛化，首次展示端到端学习系统在**全新家庭环境**中执行 10-15 分钟的长时程灵巧操作任务（如清理厨房、卧室）。

## 基本信息

- **作者**: Physical Intelligence (Kevin Black, Chelsea Finn, Sergey Levine 等)
- **发表**: arXiv 2025.04
- **领域**: 机器人学习、VLA 模型、开放世界泛化
- **链接**: https://pi.website/blog/pi05

## 研究问题

如何让 VLA 模型实现**开放世界泛化**，在从未见过的真实家庭环境中执行复杂的长时程操作任务？

核心挑战：
1. 泛化需要多层次抽象（技能迁移、场景理解、任务推理）
2. 单纯扩大机器人数据无法覆盖所有真实场景
3. 如何利用异构知识源（其他机器人、Web 数据、语义标注）

## 方法概述

### 核心思想：异构数据协同训练

```
┌─────────────────────────────────────────────────────────────┐
│                    π₀.₅ Co-Training Recipe                   │
├─────────────────────────────────────────────────────────────┤
│  Mobile Manipulator Data (MM)  │  400 小时，~100 个家庭环境   │
│  Multi-Environment Data (ME)   │  非移动机器人，更多环境       │
│  Cross-Embodiment Data (CE)    │  实验室数据 + OXE 数据集     │
│  High-Level Prediction (HL)    │  子任务标签预测              │
│  Web Data (WD)                 │  Caption, VQA, 目标定位      │
│  Verbal Instructions (VI)      │  人类语音指导（后训练）       │
└─────────────────────────────────────────────────────────────┘
```

### 模型架构

```
┌─────────────────────────────────────────────────────────────┐
│                      π₀.₅ Architecture                       │
├─────────────────────────────────────────────────────────────┤
│  VLM Backbone (PaliGemma)                                    │
│  - SigLIP (400M) 图像编码器                                   │
│  - Gemma (2B) 语言模型                                       │
├─────────────────────────────────────────────────────────────┤
│  Action Expert (300M)                                        │
│  - Flow Matching 动作生成                                     │
│  - Action Chunking (H=50)                                    │
├─────────────────────────────────────────────────────────────┤
│  分层推理 (Two-Stage Inference)                               │
│  1. 高层推理：预测子任务 (e.g., "pick up the plate")          │
│  2. 低层推理：基于子任务生成动作                              │
└─────────────────────────────────────────────────────────────┘
```

### 训练流程

**阶段 1: 预训练 (280k steps)**
- 所有动作用离散 token (FAST tokenizer)
- 混合训练：MM + ME + CE + HL + WD
- 标准自回归 next-token prediction

**阶段 2: 后训练 (80k steps)**
- 添加 Action Expert (Flow Matching)
- 混合目标：交叉熵 + Flow Matching
- 移除 CE 数据，聚焦移动操作
- 添加 Verbal Instructions (VI)

### 分层推理机制

```
用户指令: "clean the kitchen"
    ↓
[高层推理] πθ(ℓ̂|ot, ℓ) → "pick up the plate"
    ↓
[低层推理] πθ(at:t+H|ot, ℓ̂) → 连续动作序列
```

- 高层推理频率低，低层推理 50Hz
- 类似 Chain-of-Thought，但用于机器人控制
- 同一模型执行两层推理（非双模型）

## 关键创新

1. **异构数据协同训练**: 首次系统性地结合多机器人数据、Web 数据、语义预测进行 VLA 训练
2. **跨具身迁移**: 97.6% 预训练数据来自非目标平台，但成功迁移到移动操作
3. **分层 VLA 推理**: 统一架构的高层/低层推理，类似 CoT
4. **开放世界泛化**: 首次在全新真实家庭中执行 10-15 分钟长时程任务
5. **Verbal Instructions**: 人类语音指导作为新的监督信号

## 数据组成

### 预训练数据混合

| 数据源 | 描述 | 比例 |
|--------|------|------|
| MM (Mobile Manipulator) | 移动机械臂，~100 个家庭 | ~2.4% |
| ME (Multi-Environment) | 固定机械臂，多环境 | - |
| CE (Cross-Embodiment) | 实验室数据 + OXE | - |
| HL (High-Level) | 子任务标签预测 | - |
| WD (Web Data) | Caption, VQA, 定位 | - |
| **目标平台数据占比** | 移动机械臂 | **~2.4%** |

### 后训练数据混合

| 数据源 | 描述 |
|--------|------|
| MM | 成功轨迹，长度阈值过滤 |
| ME | 多环境非移动数据 |
| WD | 保持语义能力 |
| HL | 多环境子任务预测 |
| VI | 语音指导演示 (~11% of HL) |

## 机器人平台

两种移动机械臂平台：
- 4 个相机（前/后/双腕）
- 双 6 DoF 机械臂 + 平行夹爪
- 全向轮式底盘
- 升降机构
- **总自由度**: 18-19 DoF
- **控制频率**: 50 Hz (端到端，无轨迹规划)

## 实验结果

### 开放世界泛化

在 **3 个从未见过的真实家庭** 中测试：

| 任务 | 成功率 | 说明 |
|------|--------|------|
| 厨房清理 | ~70-80% | 10-15 分钟长时程 |
| 卧室清理 | ~70-80% | 整理床铺、收衣服 |
| 物品归位 | ~60-75% | 放入抽屉、水槽 |
| 挂毛巾 | 成功 | 精细灵巧操作 |

### 环境数量 Scaling

| 训练环境数 | 测试性能 |
|-----------|---------|
| 3 | ~30% |
| 12 | ~40% |
| 22 | ~45% |
| 53 | ~55% |
| 82 | ~60% |
| 104 | ~65% |
| 测试环境直接训练 | ~65% |

**关键发现**: 104 个训练环境的泛化性能接近直接在测试环境训练！

### 消融实验：数据源重要性

| 移除的数据 | 性能下降 |
|-----------|---------|
| no WD (Web Data) | 轻微（任务执行）；显著（OOD 语言跟随）|
| no ME (Multi-Env) | 显著 |
| no CE (Cross-Emb) | 显著 |
| no ME + no CE | 非常显著 |

**结论**: 跨具身迁移对泛化至关重要！

### 与 π₀ 对比

| 方法 | 平均性能 |
|------|---------|
| π₀ (300k steps) | ~35% |
| π₀-FAST+Flow | ~45% |
| **π₀.₅** | **~65%** |

### 分层推理重要性

| 高层策略 | 性能 |
|---------|------|
| π₀.₅ (完整) | ~65% |
| implicit HL (训练有，推理无) | ~60% |
| no HL (训练推理都无) | ~45% |
| GPT-4 作为高层 | ~40% |
| Human Oracle | ~62% |

**发现**:
- π₀.₅ 甚至超越人类 Oracle！
- 即使不做高层推理，训练时包含 HL 数据也有帮助
- Verbal Instructions 占 HL 数据仅 11%，但移除后性能显著下降

## 个人评价

### 优点
1. **首次开放世界泛化**: 在全新真实家庭执行长时程任务，里程碑式突破
2. **异构知识迁移**: 证明了跨具身、Web 数据、语义预测的有效性
3. **数据效率高**: 仅 2.4% 目标平台数据实现强泛化
4. **分层推理有效**: 统一架构的 CoT-style 推理
5. **实验充分**: 消融实验清晰展示各组件贡献

### 不足
1. **闭源**: 模型、数据都未开放
2. **硬件限制**: 需要特定移动机械臂平台
3. **Prompt 简单**: 目前只支持简单高层指令
4. **上下文有限**: 无跨房间记忆能力
5. **失败模式**: 部分环境仍有持续挑战（陌生门把手、遮挡问题等）

### 启发
- **异构数据协同训练** 是通向开放世界泛化的关键
- 跨具身迁移非常有效，甚至超过在目标环境直接训练
- 分层推理（CoT for robotics）值得深入研究
- Verbal Instructions 是高效的监督信号
- Web 数据主要帮助 OOD 物体的语义理解

## 与 π₀ 的对比

| 方面 | π₀ | π₀.₅ |
|------|-----|------|
| 泛化目标 | 跨任务/机器人 | 开放世界 (新家庭) |
| 训练数据 | 机器人数据为主 | 异构数据协同 |
| 推理方式 | 单层 | 分层 (高层+低层) |
| Web 数据 | 预训练继承 | 显式协同训练 |
| 新监督信号 | - | Verbal Instructions |
| 任务时长 | 分钟级 | 10-15 分钟 |
| 部署场景 | 训练相似环境 | 全新真实家庭 |

## 后续版本

- **π₀.6**: VLA That Learns From Experience (学习从经验中改进)

## 技术细节

### Flow Matching 与 FAST Token 混合

预训练：仅 FAST token (离散化)
```
L = H(x_{1:M}, f^ℓ_θ(o_t, ℓ))  # 交叉熵
```

后训练：FAST + Flow Matching
```
L = H(...) + α·||ω - a_{t:t+H} - f^a_θ(a^{τ,ω}_{t:t+H}, o_t, ℓ)||²
```
- α = 10.0
- 10 步去噪积分
- 时间步采样：Beta 分布，强调低时间步

### 数据增强

```python
transforms = [
    RandomCrop(0.95),
    Resize(width, height),
    Rotate((-5, 5)),
    ColorJitter(brightness=0.3, contrast=0.4, saturation=0.5),
]
```

### 注意力模式

- VLM embeddings: 不关注 Action Expert
- Action Expert: 关注 VLM prefix + 自身
- FAST tokens 与 Flow Matching tokens 不互相关注

---

*笔记创建时间: 2025-12*
